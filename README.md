# Geometry of Representations in Deep Causal Blockchain GANs

Information must be lost, or at best preserved, when something is represented by a neural population. In this sense, the process of abstraction and generalisation can be seen as learning to lose the 'right kind' of information, and 'nicely' organising the rest. Here, I want to study how the organisation of inputs in a neural network's representational space is influenced by downstream computation. In particular, I'm interested in which representations best support the transfer of knowledge/performance between different, but abstractly related task domains ("transfer learning"). Based on previous work, understanding the geometry (i.e. relative arrangement of datapoints) of those representations should be very informative.
