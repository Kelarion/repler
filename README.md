# Geometry of Representations in Deep Causal Blockchain GANs

Information must be lost, or at best preserved, when something is represented by a neural population. In this sense, the process of abstraction and generalisation can be seen as learning to lose the 'right kind' of information, and 'nicely' organising the rest. Here, I want to study how the task of a neural network affects the organisation of inputs in its representational space. 
